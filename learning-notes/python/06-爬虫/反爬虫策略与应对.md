# 反爬虫策略与应对

> 学习常见的反爬虫机制和应对方法

## 1. 常见反爬虫机制

### 1.1 User-Agent 检测

```python
import requests

# 使用真实浏览器 User-Agent
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
}
response = requests.get(url, headers=headers)
```

### 1.2 IP 限制

```python
# 使用代理
proxies = {
    'http': 'http://proxy.example.com:8080',
    'https': 'https://proxy.example.com:8080'
}
response = requests.get(url, proxies=proxies)

# 代理池
import random
proxy_pool = [
    'http://proxy1.com:8080',
    'http://proxy2.com:8080',
    'http://proxy3.com:8080'
]
proxy = random.choice(proxy_pool)
```

### 1.3 Cookie 和 Session

```python
session = requests.Session()
session.get('https://example.com/login', data={'user': 'xxx', 'pass': 'xxx'})
response = session.get('https://example.com/protected')
```

## 2. JavaScript 渲染

### 2.1 使用 Selenium

```python
from selenium import webdriver
from selenium.webdriver.common.by import By

driver = webdriver.Chrome()
driver.get('https://example.com')
element = driver.find_element(By.ID, 'content')
print(element.text)
driver.quit()
```

### 2.2 使用 Playwright

```python
from playwright.sync_api import sync_playwright

with sync_playwright() as p:
    browser = p.chromium.launch()
    page = browser.new_page()
    page.goto('https://example.com')
    content = page.content()
    browser.close()
```

## 3. 验证码处理

### 3.1 图片验证码

```python
import pytesseract
from PIL import Image

# OCR识别
image = Image.open('captcha.png')
text = pytesseract.image_to_string(image)
```

### 3.2 滑动验证码

```python
# 使用 selenium 模拟滑动
from selenium.webdriver import ActionChains

slider = driver.find_element(By.CLASS_NAME, 'slider')
ActionChains(driver).drag_and_drop_by_offset(
    slider, 200, 0
).perform()
```

## 4. 请求频率控制

### 4.1 延迟请求

```python
import time
import random

for url in urls:
    response = requests.get(url)
    time.sleep(random.uniform(1, 3))  # 随机延迟
```

### 4.2 使用队列控制

```python
import asyncio
from asyncio import Semaphore

semaphore = Semaphore(5)  # 最多5个并发

async def fetch(url):
    async with semaphore:
        await asyncio.sleep(1)  # 延迟
        # 请求逻辑
```

## 5. 总结

反爬虫应对策略：
- **User-Agent**：使用真实浏览器标识
- **代理**：使用代理池轮换IP
- **Session**：保持登录状态
- **JavaScript**：使用Selenium/Playwright
- **验证码**：OCR或人工处理
- **频率控制**：合理延迟和并发控制

