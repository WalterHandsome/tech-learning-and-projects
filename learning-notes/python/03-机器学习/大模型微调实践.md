# 大模型微调实践

> 学习如何对预训练大语言模型进行微调以适应特定任务

## 1. 微调概述

大模型微调（Fine-tuning）是在预训练模型基础上，使用特定领域数据对模型进行进一步训练的过程。

### 1.1 微调类型

- **全量微调（Full Fine-tuning）**：更新所有参数
- **参数高效微调（PEFT）**：
  - LoRA（Low-Rank Adaptation）
  - QLoRA（Quantized LoRA）
  - Adapter
  - Prompt Tuning

### 1.2 微调场景

- 领域适应：医疗、法律、金融等
- 任务适应：问答、摘要、翻译等
- 风格适应：正式、非正式、技术文档等

## 2. 环境准备

### 2.1 安装依赖

```bash
pip install transformers
pip install datasets
pip install peft
pip install bitsandbytes  # 量化支持
pip install accelerate
pip install torch
```

### 2.2 检查GPU

```python
import torch

print(f"CUDA可用: {torch.cuda.is_available()}")
print(f"GPU数量: {torch.cuda.device_count()}")
if torch.cuda.is_available():
    print(f"GPU名称: {torch.cuda.get_device_name(0)}")
```

## 3. 数据准备

### 3.1 数据格式

```python
from datasets import Dataset

# 示例数据
data = {
    "instruction": [
        "解释什么是机器学习",
        "如何优化Python代码性能",
        "什么是RESTful API"
    ],
    "input": ["", "", ""],
    "output": [
        "机器学习是人工智能的一个分支...",
        "优化Python代码性能的方法包括...",
        "RESTful API是一种架构风格..."
    ]
}

dataset = Dataset.from_dict(data)
```

### 3.2 数据预处理

```python
def preprocess_function(examples, tokenizer, max_length=512):
    """预处理函数"""
    inputs = []
    targets = []
    
    for instruction, input_text, output in zip(
        examples["instruction"],
        examples["input"],
        examples["output"]
    ):
        # 构建提示
        if input_text:
            prompt = f"指令: {instruction}\n输入: {input_text}\n输出:"
        else:
            prompt = f"指令: {instruction}\n输出:"
        
        inputs.append(prompt)
        targets.append(output)
    
    # Tokenize
    model_inputs = tokenizer(
        inputs,
        max_length=max_length,
        truncation=True,
        padding="max_length"
    )
    
    labels = tokenizer(
        targets,
        max_length=max_length,
        truncation=True,
        padding="max_length"
    )
    
    model_inputs["labels"] = labels["input_ids"]
    return model_inputs

# 应用预处理
tokenized_dataset = dataset.map(
    lambda x: preprocess_function(x, tokenizer),
    batched=True
)
```

## 4. LoRA 微调

### 4.1 LoRA 原理

LoRA（Low-Rank Adaptation）通过低秩矩阵分解来减少可训练参数：

```python
from peft import LoraConfig, get_peft_model, TaskType
from transformers import AutoModelForCausalLM, AutoTokenizer

# 加载模型和tokenizer
model_name = "meta-llama/Llama-2-7b-hf"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    load_in_8bit=True,  # 8-bit量化
    device_map="auto"
)

# 配置LoRA
lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=8,  # 秩
    lora_alpha=16,  # 缩放参数
    lora_dropout=0.1,
    target_modules=["q_proj", "v_proj"]  # 目标模块
)

# 应用LoRA
model = get_peft_model(model, lora_config)
model.print_trainable_parameters()
```

### 4.2 训练配置

```python
from transformers import TrainingArguments, Trainer

training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    warmup_steps=100,
    logging_steps=10,
    save_steps=500,
    evaluation_strategy="steps",
    eval_steps=500,
    learning_rate=2e-4,
    fp16=True,  # 混合精度训练
    push_to_hub=False,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    data_collator=lambda x: {
        "input_ids": torch.stack([f["input_ids"] for f in x]),
        "attention_mask": torch.stack([f["attention_mask"] for f in x]),
        "labels": torch.stack([f["labels"] for f in x])
    }
)

# 开始训练
trainer.train()
```

## 5. QLoRA 微调

### 5.1 QLoRA 配置

QLoRA 结合了4-bit量化和LoRA：

```python
from transformers import BitsAndBytesConfig
from peft import LoraConfig, get_peft_model

# 4-bit量化配置
bnb_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# 加载模型（4-bit）
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map="auto"
)

# LoRA配置
lora_config = LoraConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj"],
    lora_dropout=0.1,
    bias="none",
    task_type="CAUSAL_LM"
)

model = get_peft_model(model, lora_config)
```

## 6. 全量微调

### 6.1 全量微调实现

```python
from transformers import AutoModelForCausalLM, Trainer, TrainingArguments

# 加载完整模型
model = AutoModelForCausalLM.from_pretrained(model_name)

# 训练参数
training_args = TrainingArguments(
    output_dir="./full_finetune",
    num_train_epochs=3,
    per_device_train_batch_size=2,
    gradient_accumulation_steps=8,
    learning_rate=5e-5,
    warmup_steps=100,
    logging_steps=10,
    save_strategy="epoch",
    fp16=True,
    deepspeed="ds_config.json"  # 使用DeepSpeed
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset,
)

trainer.train()
```

## 7. 评估和测试

### 7.1 评估指标

```python
from transformers import pipeline

# 创建生成管道
generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer,
    device=0
)

# 测试
test_prompt = "指令: 解释什么是深度学习\n输出:"
result = generator(
    test_prompt,
    max_length=200,
    num_return_sequences=1,
    temperature=0.7
)

print(result[0]["generated_text"])
```

### 7.2 批量评估

```python
def evaluate_model(model, tokenizer, test_dataset):
    """评估模型"""
    model.eval()
    results = []
    
    for example in test_dataset:
        prompt = example["instruction"]
        expected = example["output"]
        
        inputs = tokenizer(prompt, return_tensors="pt")
        outputs = model.generate(
            **inputs,
            max_length=200,
            temperature=0.7
        )
        
        generated = tokenizer.decode(outputs[0], skip_special_tokens=True)
        results.append({
            "prompt": prompt,
            "expected": expected,
            "generated": generated
        })
    
    return results
```

## 8. 模型保存和加载

### 8.1 保存LoRA权重

```python
# 保存LoRA适配器
model.save_pretrained("./lora_model")

# 只保存适配器权重
model.save_pretrained("./lora_weights", save_only_model=True)
```

### 8.2 加载微调模型

```python
from peft import PeftModel

# 加载基础模型
base_model = AutoModelForCausalLM.from_pretrained(model_name)

# 加载LoRA权重
model = PeftModel.from_pretrained(base_model, "./lora_model")

# 合并权重（可选）
model = model.merge_and_unload()
model.save_pretrained("./merged_model")
```

## 9. 实际应用示例

### 9.1 代码生成微调

```python
# 准备代码生成数据
code_data = {
    "instruction": [
        "写一个Python函数计算斐波那契数列",
        "实现一个快速排序算法",
        "创建一个RESTful API端点"
    ],
    "output": [
        "def fibonacci(n):\n    if n <= 1:\n        return n\n    return fibonacci(n-1) + fibonacci(n-2)",
        "def quicksort(arr):\n    if len(arr) <= 1:\n        return arr\n    pivot = arr[len(arr)//2]\n    ...",
        "@app.route('/api/users', methods=['GET'])\ndef get_users():\n    ..."
    ]
}

# 微调代码生成模型
# ... (使用前面的训练流程)
```

### 9.2 领域适应微调

```python
# 医疗领域数据
medical_data = {
    "instruction": [
        "解释什么是糖尿病",
        "高血压的治疗方法有哪些",
        "如何预防感冒"
    ],
    "output": [
        "糖尿病是一种慢性代谢性疾病...",
        "高血压的治疗方法包括药物治疗和生活方式改变...",
        "预防感冒的方法包括..."
    ]
}

# 微调医疗领域模型
# ... (使用前面的训练流程)
```

## 10. 最佳实践

### 10.1 数据质量

- 确保数据质量和多样性
- 平衡不同主题的数据
- 清理和标准化数据格式

### 10.2 超参数调优

```python
# 学习率调度
from transformers import get_linear_schedule_with_warmup

optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4)
scheduler = get_linear_schedule_with_warmup(
    optimizer,
    num_warmup_steps=100,
    num_training_steps=1000
)
```

### 10.3 防止过拟合

- 使用验证集监控
- 早停（Early Stopping）
- 数据增强
- Dropout正则化

## 11. 总结

大模型微调的关键要点：
- **选择合适的微调方法**：根据资源选择LoRA或全量微调
- **准备高质量数据**：数据质量决定微调效果
- **合理设置超参数**：学习率、批次大小等
- **持续监控和评估**：使用验证集跟踪性能
- **保存和版本管理**：保存检查点和最终模型

通过合理微调，可以让通用大模型适应特定领域和任务。

