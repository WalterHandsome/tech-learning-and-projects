# 线程池与进程池

> 使用线程池和进程池高效管理并发任务

## 1. 线程池（ThreadPoolExecutor）

### 1.1 基础使用

```python
from concurrent.futures import ThreadPoolExecutor, as_completed
import time

def task(n):
    """模拟任务"""
    print(f"任务 {n} 开始")
    time.sleep(2)
    print(f"任务 {n} 完成")
    return f"结果 {n}"

# 创建线程池
with ThreadPoolExecutor(max_workers=3) as executor:
    # 提交任务
    futures = [executor.submit(task, i) for i in range(5)]
    
    # 获取结果
    for future in as_completed(futures):
        result = future.result()
        print(f"收到结果: {result}")
```

### 1.2 使用 map 方法

```python
def square(x):
    return x ** 2

with ThreadPoolExecutor(max_workers=4) as executor:
    # 使用map并行处理
    results = executor.map(square, range(10))
    print(list(results))  # [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
```

### 1.3 异常处理

```python
def risky_task(n):
    if n == 5:
        raise ValueError(f"任务 {n} 失败")
    return n * 2

with ThreadPoolExecutor(max_workers=3) as executor:
    futures = {executor.submit(risky_task, i): i for i in range(10)}
    
    for future in as_completed(futures):
        task_id = futures[future]
        try:
            result = future.result()
            print(f"任务 {task_id} 成功: {result}")
        except Exception as e:
            print(f"任务 {task_id} 失败: {e}")
```

### 1.4 回调函数

```python
def on_complete(future):
    """完成回调"""
    try:
        result = future.result()
        print(f"任务完成，结果: {result}")
    except Exception as e:
        print(f"任务失败: {e}")

with ThreadPoolExecutor(max_workers=3) as executor:
    future = executor.submit(task, 1)
    future.add_done_callback(on_complete)
    future.result()  # 等待完成
```

## 2. 进程池（ProcessPoolExecutor）

### 2.1 基础使用

```python
from concurrent.futures import ProcessPoolExecutor
import multiprocessing

def cpu_intensive_task(n):
    """CPU密集型任务"""
    result = sum(i * i for i in range(n))
    return result

if __name__ == "__main__":
    # 创建进程池
    with ProcessPoolExecutor(max_workers=multiprocessing.cpu_count()) as executor:
        futures = [executor.submit(cpu_intensive_task, 1000000) for _ in range(8)]
        results = [future.result() for future in futures]
        print(f"结果: {results}")
```

### 2.2 进程间通信

```python
from multiprocessing import Manager

def worker(shared_dict, key, value):
    """工作进程"""
    shared_dict[key] = value
    return f"设置 {key} = {value}"

if __name__ == "__main__":
    manager = Manager()
    shared_dict = manager.dict()
    
    with ProcessPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(worker, shared_dict, f"key_{i}", i)
            for i in range(10)
        ]
        
        for future in as_completed(futures):
            print(future.result())
    
    print(f"共享字典: {dict(shared_dict)}")
```

## 3. 自定义线程池

### 3.1 实现线程池

```python
import threading
from queue import Queue
import time

class CustomThreadPool:
    def __init__(self, num_threads):
        self.num_threads = num_threads
        self.task_queue = Queue()
        self.threads = []
        self.shutdown = False
        
        # 启动工作线程
        for _ in range(num_threads):
            thread = threading.Thread(target=self._worker)
            thread.daemon = True
            thread.start()
            self.threads.append(thread)
    
    def _worker(self):
        """工作线程"""
        while not self.shutdown:
            try:
                task, args, kwargs = self.task_queue.get(timeout=1)
                try:
                    result = task(*args, **kwargs)
                    print(f"任务完成: {result}")
                except Exception as e:
                    print(f"任务失败: {e}")
                finally:
                    self.task_queue.task_done()
            except:
                continue
    
    def submit(self, task, *args, **kwargs):
        """提交任务"""
        self.task_queue.put((task, args, kwargs))
    
    def shutdown_pool(self):
        """关闭线程池"""
        self.shutdown = True
        self.task_queue.join()

# 使用
pool = CustomThreadPool(3)
for i in range(10):
    pool.submit(task, i)
pool.shutdown_pool()
```

## 4. 性能对比

### 4.1 I/O密集型任务

```python
import requests
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import time

def fetch_url(url):
    """获取URL内容"""
    response = requests.get(url)
    return len(response.content)

urls = ["https://www.example.com"] * 20

# 串行执行
start = time.time()
results = [fetch_url(url) for url in urls]
serial_time = time.time() - start
print(f"串行执行时间: {serial_time:.2f}秒")

# 线程池
start = time.time()
with ThreadPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(fetch_url, urls))
thread_time = time.time() - start
print(f"线程池执行时间: {thread_time:.2f}秒")

# 进程池
start = time.time()
with ProcessPoolExecutor(max_workers=10) as executor:
    results = list(executor.map(fetch_url, urls))
process_time = time.time() - start
print(f"进程池执行时间: {process_time:.2f}秒")
```

### 4.2 CPU密集型任务

```python
def compute_fibonacci(n):
    """计算斐波那契数列"""
    if n <= 1:
        return n
    return compute_fibonacci(n-1) + compute_fibonacci(n-2)

numbers = [35] * 4

# 串行
start = time.time()
results = [compute_fibonacci(n) for n in numbers]
serial_time = time.time() - start

# 线程池（受GIL限制）
start = time.time()
with ThreadPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(compute_fibonacci, numbers))
thread_time = time.time() - start

# 进程池
start = time.time()
with ProcessPoolExecutor(max_workers=4) as executor:
    results = list(executor.map(compute_fibonacci, numbers))
process_time = time.time() - start

print(f"串行: {serial_time:.2f}秒")
print(f"线程池: {thread_time:.2f}秒")
print(f"进程池: {process_time:.2f}秒")
```

## 5. 最佳实践

### 5.1 选择合适的执行器

- **ThreadPoolExecutor**：I/O密集型任务
- **ProcessPoolExecutor**：CPU密集型任务

### 5.2 资源管理

```python
# 使用上下文管理器确保资源释放
with ThreadPoolExecutor(max_workers=5) as executor:
    futures = [executor.submit(task, i) for i in range(10)]
    # 自动等待所有任务完成并清理资源
```

### 5.3 超时控制

```python
from concurrent.futures import TimeoutError

with ThreadPoolExecutor(max_workers=3) as executor:
    future = executor.submit(long_running_task)
    try:
        result = future.result(timeout=5)  # 5秒超时
    except TimeoutError:
        print("任务超时")
        future.cancel()
```

## 6. 总结

线程池和进程池提供了高效的并发任务管理：
- **线程池**：适合I/O密集型任务，共享内存
- **进程池**：适合CPU密集型任务，真正的并行
- **资源管理**：使用上下文管理器自动清理
- **异常处理**：正确处理任务异常
- **性能优化**：根据任务类型选择合适的执行器

