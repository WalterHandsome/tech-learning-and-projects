# 数据清洗与预处理

> 数据清洗和预处理是数据分析的关键步骤

## 1. 数据清洗概述

数据清洗包括：
- 处理缺失值
- 处理重复数据
- 处理异常值
- 数据类型转换
- 数据标准化

## 2. 处理缺失值

### 2.1 检测缺失值

```python
import pandas as pd
import numpy as np

df = pd.DataFrame({
    'A': [1, 2, np.nan, 4],
    'B': [5, np.nan, 7, 8],
    'C': [9, 10, 11, np.nan]
})

# 检测缺失值
print(df.isnull())
print(df.isnull().sum())
print(df.isnull().sum() / len(df))  # 缺失比例
```

### 2.2 删除缺失值

```python
# 删除包含缺失值的行
df.dropna()

# 删除所有值都为NaN的行
df.dropna(how='all')

# 删除特定列有缺失值的行
df.dropna(subset=['A', 'B'])

# 删除缺失值超过阈值的行
df.dropna(thresh=2)  # 至少2个非空值
```

### 2.3 填充缺失值

```python
# 用固定值填充
df.fillna(0)

# 用前一个值填充
df.fillna(method='ffill')

# 用后一个值填充
df.fillna(method='bfill')

# 用均值填充
df.fillna(df.mean())

# 用中位数填充
df.fillna(df.median())

# 用众数填充
df.fillna(df.mode().iloc[0])

# 用插值填充
df.interpolate()
```

## 3. 处理重复数据

### 3.1 检测重复

```python
# 检测完全重复的行
df.duplicated()

# 检测特定列的重复
df.duplicated(subset=['A', 'B'])

# 统计重复数量
df.duplicated().sum()
```

### 3.2 删除重复

```python
# 删除重复行
df.drop_duplicates()

# 保留第一次出现的
df.drop_duplicates(keep='first')

# 保留最后一次出现的
df.drop_duplicates(keep='last')

# 删除所有重复
df.drop_duplicates(keep=False)
```

## 4. 处理异常值

### 4.1 检测异常值

```python
# 使用IQR方法
Q1 = df['A'].quantile(0.25)
Q3 = df['A'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['A'] < lower_bound) | (df['A'] > upper_bound)]

# 使用Z-score
from scipy import stats
z_scores = np.abs(stats.zscore(df['A']))
outliers = df[z_scores > 3]
```

### 4.2 处理异常值

```python
# 删除异常值
df_clean = df[(df['A'] >= lower_bound) & (df['A'] <= upper_bound)]

# 用边界值替换
df['A'] = df['A'].clip(lower=lower_bound, upper=upper_bound)

# 用中位数替换
median = df['A'].median()
df.loc[df['A'] > upper_bound, 'A'] = median
```

## 5. 数据类型转换

### 5.1 类型转换

```python
# 转换为数值类型
df['A'] = pd.to_numeric(df['A'], errors='coerce')

# 转换为日期类型
df['date'] = pd.to_datetime(df['date'])

# 转换为分类类型
df['category'] = df['category'].astype('category')
```

### 5.2 字符串处理

```python
# 去除空格
df['text'] = df['text'].str.strip()

# 转换为小写
df['text'] = df['text'].str.lower()

# 替换字符
df['text'] = df['text'].str.replace('old', 'new')

# 提取数字
df['number'] = df['text'].str.extract('(\d+)')
```

## 6. 数据标准化

### 6.1 归一化

```python
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
df_normalized = pd.DataFrame(
    scaler.fit_transform(df[['A', 'B']]),
    columns=['A', 'B']
)
```

### 6.2 标准化

```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
df_standardized = pd.DataFrame(
    scaler.fit_transform(df[['A', 'B']]),
    columns=['A', 'B']
)
```

## 7. 特征工程

### 7.1 创建新特征

```python
# 从日期提取特征
df['year'] = df['date'].dt.year
df['month'] = df['date'].dt.month
df['day_of_week'] = df['date'].dt.dayofweek

# 组合特征
df['total'] = df['A'] + df['B']
df['ratio'] = df['A'] / df['B']

# 分箱
df['age_group'] = pd.cut(df['age'], bins=[0, 18, 35, 60, 100], labels=['少年', '青年', '中年', '老年'])
```

### 7.2 编码分类变量

```python
# One-Hot编码
df_encoded = pd.get_dummies(df, columns=['category'])

# Label编码
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df['category_encoded'] = le.fit_transform(df['category'])
```

## 8. 数据清洗流程

### 8.1 完整流程

```python
def clean_data(df):
    # 1. 删除完全重复的行
    df = df.drop_duplicates()
    
    # 2. 处理缺失值
    df = df.fillna(df.median())
    
    # 3. 处理异常值
    for col in df.select_dtypes(include=[np.number]).columns:
        Q1 = df[col].quantile(0.25)
        Q3 = df[col].quantile(0.75)
        IQR = Q3 - Q1
        lower = Q1 - 1.5 * IQR
        upper = Q3 + 1.5 * IQR
        df[col] = df[col].clip(lower=lower, upper=upper)
    
    # 4. 数据类型转换
    df['date'] = pd.to_datetime(df['date'])
    
    # 5. 字符串清理
    if 'text' in df.columns:
        df['text'] = df['text'].str.strip().str.lower()
    
    return df
```

## 9. 总结

数据清洗关键步骤：
- **缺失值处理**：删除或填充
- **重复数据**：检测和删除
- **异常值**：检测和处理
- **类型转换**：确保数据类型正确
- **标准化**：归一化和标准化
- **特征工程**：创建新特征
- **编码**：分类变量编码

良好的数据清洗是数据分析成功的基础。

